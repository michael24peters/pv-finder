{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%matplotlib widget\n",
    "## with %matplotlib notebook: seems to require ipympl as part of environment, either\n",
    "## part of the conda environment or \"pip install ipympl\"\n",
    "## otherwise, does not show ANY plots in notebook, plt.savefig() works\n",
    "%matplotlib notebook  \n",
    "##%matplotlib inline    ## --plt.savefig()  works, but re-sizing does NOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a short demo to illustrate execution.   For odd historical reasons, it uses \"toy Monte Carlo\" (simulated data)for \"training\" and \"full LHCB MC\" for validation.\n",
    "\n",
    "The network architecture is a \"simple\" model that uses 1 input channel (the KDE [kernel density estimator] but from the track parameters) feeding 5 convolutional layers followed by a fully connected layer.\n",
    "\n",
    "In today's version, the network will start with weights from a previously trained version.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current GPU usage. Please try to be nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 24 22:07:15 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN V             Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 28%   32C    P2    32W / 250W |   1107MiB / 12066MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:83:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P0    27W / 250W |     10MiB / 16280MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  TITAN V             Off  | 00000000:84:00.0 Off |                  N/A |\r\n",
      "| 28%   35C    P8    25W / 250W |  10808MiB / 12066MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     42274      C   ...a/conda/envs/goofit-june2020/bin/python  1095MiB |\r\n",
      "|    2     22163      C   ...a/conda/envs/goofit-june2020/bin/python  2457MiB |\r\n",
      "|    2     43718      C   ...a/conda/envs/goofit-june2020/bin/python  8339MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WARNING**: The card numbers here are *not* the same as in CUDA. You have been warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "# Python 3 standard library\n",
    "from pathlib import Path\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "'''\n",
    "HELPER FUNCTIONS\n",
    "'''\n",
    "# From model/collectdata.py\n",
    "from model.collectdata_mdsA import collect_data\n",
    "\n",
    "# From model/loss.py\n",
    "##from loss import Loss\n",
    "from model.alt_loss_A import Loss\n",
    "\n",
    "# From model/training.py\n",
    "from model.training import trainNet, select_gpu, Results\n",
    "\n",
    "# From model/models.py\n",
    "##  will start with model from TwoFeatures_CNN6Layer_A in the first instance\n",
    "##  see relevant cell below\n",
    "\n",
    "from model.models_mjp_19November20 import ThreeFeature_All_CNN6Layer_A as ModelA\n",
    "from model.models_mjp_19November20 import ThreeFeature_All_CNN6Layer_A1 as ModelA1\n",
    "from model.models_mjp_19November20 import ThreeFeature_All_CNN6Layer_E as ModelE\n",
    "from model.models_mjp_19November20 import ThreeFeature_All_CNN8Layer_W as ModelW\n",
    "from model.models_mjp_26December20 import ThreeFeature_All_CNN10Layer_X as ModelX\n",
    "from model.models_mjp_26December20 import ThreeFeature_All_CNN8Layer_Y as ModelY\n",
    "\n",
    "# From model/utilities.py\n",
    "from model.utilities import load_full_state, count_parameters, Params\n",
    "\n",
    "from model.plots import dual_train_plots, replace_in_ax\n",
    "\n",
    "## adds image of model architecture\n",
    "import hiddenlayer as HL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Torch device configuration. All tensors and model parameters need to know where to be put.\n",
    "This takes a BUS ID number: The BUS ID is the same as the listing at the top of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 available GPUs (initially using device 0):\n",
      "  0 TITAN V\n"
     ]
    }
   ],
   "source": [
    "device = select_gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params order - batch size, epochs, lr, epoch_start (which is usually set to 0)\n",
    "args = Params(128, 50, 5e-5, 3420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the dataset, split into parts, then move to device (see `collectdata.py` in the `../model` directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded /share/lazy/sokoloff/ML-data_A/Aug14_80K_train.h5 in 3.536 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-68060ea7e35c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m                             \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                             \u001b[0mload_XandXsq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                             load_xy=True)\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Validation dataset. You can slice to reduce the size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pv-finder_experimental/notebooks/model/collectdata_mdsA.py\u001b[0m in \u001b[0;36mcollect_data\u001b[0;34m(batch_size, dtype, device, masking, slice, load_xy, load_XandXsq, *files, **kargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m## a is *probably* 4000 and b is *probably* N, but it could be the other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m## way around;  check iwth .shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kernel\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mXsq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0;31m## this simply squares each element of X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## newer vernacular\n",
    "## Training dataset. You can put as many files here as desired.\n",
    "\n",
    "## in this DEMO example we use only one 80K training set -- the model starts with well-trained weights,\n",
    "## and using a smaller training set reduces both the time to load the data and the time to train an epoch\n",
    "##  set the option load_XandXsq = True to use both DKE and KDE^2 as input features\n",
    "train_loader = collect_data('/share/lazy/sokoloff/ML-data_A/Aug14_80K_train.h5',\n",
    "                             '/share/lazy/sokoloff/ML-data_AA/Oct03_80K_train.h5',\n",
    "#                             '/share/lazy/sokoloff/ML-data_AA/Oct03_40K_train.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_1.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_3.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_4.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_5.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_6.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_7.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_8.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_9.h5',\n",
    "                            #'/share/lazy/sokoloff/ML-data_AA/Oct03_80K2_train.h5',\n",
    "                             batch_size=args.batch_size,\n",
    "## if we are using a larger dataset (240K events, with the datasets above, and 11 GB  of GPU memory),\n",
    "## not the dataset will overflow the GPU memory; device=device will allow the data to move back\n",
    "## and forth between the CPU and GPU memory. While this allows use of a larger dataset, it slows\n",
    "## down performance by about 10%.  So comment out when not needed.\n",
    "## \n",
    "                            #device=device,\n",
    "                            masking=True, shuffle=True,\n",
    "                            load_XandXsq=True,\n",
    "                            load_xy=True)\n",
    "\n",
    "# Validation dataset. You can slice to reduce the size.\n",
    "## dataAA -> /share/lazy/sokoloff/ML-data_AA/\n",
    "val_loader = collect_data('/share/lazy/sokoloff/ML-data_AA/Oct03_20K_val.h5',\n",
    "## mds val_loader = collect_data('dataAA/HLT1CPU_1kevts_val.h5',\n",
    "\n",
    "                          batch_size=args.batch_size,\n",
    "                          slice=slice(256 * 39),\n",
    "                          #device=device,\n",
    "                          masking=True, shuffle=False,\n",
    "                          load_XandXsq=True,\n",
    "                          load_xy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a model, use multiple GPUs if they are VISIBLE, and move the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ModelY()\n",
    "\n",
    "#summary(model.to(device), (1, 4000))\n",
    "\n",
    "mlflow.tracking.set_tracking_uri('file:/share/lazy/pv-finder_model_repo')\n",
    "mlflow.set_experiment('Four Feature AllCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the model's weight matricies to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  mds 200121 loss = Loss(epsilon=1e-5,coefficient=1.0)\n",
    "loss = Loss(epsilon=1e-5,coefficient=9.0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "##  use the first five layers from a pre-existing model\n",
    "##  see example at https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113\n",
    "##   ML -> /share/lazy/sokoloff/ML\n",
    "\n",
    "#path = 'run_stats.pyt'\n",
    "#load_full_state(model, optimizer, path)\n",
    "# For other pretrained models, go to MLFlow and find the path for \"run_stats.pyt\"\n",
    "pretrained_dict = '/share/lazy/pv-finder_model_repo/12/6e49222f5c5a405ba2f753b4fe77a835/artifacts/run_stats.pyt'\n",
    "load_full_state(model, optimizer, pretrained_dict, freeze_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the model's weight matricies to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \n",
    "\n",
    "\n",
    "\n",
    "The body of this loop runs once per epoch. Results is a named tuple of values (loss per epoch for training and validation, time each). Start by setting up a plot first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax, tax, lax, lines = dual_train_plots()\n",
    "fig = ax.figure\n",
    "plt.tight_layout()\n",
    "# This gets built up during the run - do not rerun this cell\n",
    "results = pd.DataFrame([], columns=Results._fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "avgEff=0\n",
    "avgFP=0\n",
    "print('for model: ', model)   \n",
    "run_name = 'Model Y (PA)'\n",
    "# Create an mlflow run\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters of the model\n",
    "    for key, value in vars(args).items():\n",
    "        print(key, value)\n",
    "        mlflow.log_param(key, value)\n",
    "    \n",
    "    # Log parameter count in the model\n",
    "    mlflow.log_param('Parameters', count_parameters(model))\n",
    "    \n",
    "    # Begin run\n",
    "    for result in trainNet(model, optimizer, loss,\n",
    "                            train_loader, val_loader,\n",
    "                            args.epochs+args.epoch_start, epoch_start=args.epoch_start,\n",
    "                            notebook=True, device=device):\n",
    "\n",
    "        result = result._asdict()\n",
    "        results = results.append(pd.Series(result), ignore_index=True)\n",
    "    \n",
    "        xs = results.index\n",
    "    \n",
    "        # Update the plot above\n",
    "        lines['train'].set_data(results.index,results.cost)\n",
    "        lines['val'].set_data(results.index,results.val)\n",
    "    \n",
    "        #filter first cost epoch (can be really large)\n",
    "        max_cost = max(max(results.cost if len(results.cost)<2 else results.cost[1:]), max(results.val))\n",
    "        min_cost = min(min(results.cost), min(results.val))\n",
    "    \n",
    "        # The plot limits need updating too\n",
    "        ax.set_ylim(min_cost*.9, max_cost*1.1)  \n",
    "        ax.set_xlim(-.5, len(results.cost) - .5)\n",
    "    \n",
    "        replace_in_ax(lax, lines['eff'], xs, results['eff_val'].apply(lambda x: x.eff_rate))\n",
    "        replace_in_ax(tax, lines['fp'], xs, results['eff_val'].apply(lambda x: x.fp_rate))\n",
    "    \n",
    "        # Redraw the figure\n",
    "        fig.canvas.draw()\n",
    "            \n",
    "        ## MLFLOW ##\n",
    "        # Log metrics\n",
    "        mlflow.log_metric('Efficiency', result['eff_val'].eff_rate, result['epoch'])\n",
    "        mlflow.log_metric('False Positive Rate',  result['eff_val'].fp_rate, result['epoch'])\n",
    "        mlflow.log_metric('Validation Loss',  result['val'], result['epoch'])\n",
    "        mlflow.log_metric('Training Loss',  result['cost'], result['epoch'])\n",
    "        \n",
    "        print('Result epoch: ', result['epoch'])\n",
    "        if(result['epoch'] >= args.epochs + args.epoch_start - 10):\n",
    "            avgEff += result['eff_val'].eff_rate\n",
    "            avgFP += result['eff_val'].fp_rate\n",
    "           \n",
    "        if(result['epoch'] == args.epochs + args.epoch_start - 1):\n",
    "            print('Averaging...\\n')\n",
    "            avgEff /= 10\n",
    "            avgFP /= 10\n",
    "            mlflow.log_metric('10 Efficiency Average', avgEff)\n",
    "            mlflow.log_metric('10 False Positive Average', avgFP)\n",
    "            \n",
    "        print('Average Eff: ', avgEff)\n",
    "        print('Average FP Rate: ', avgFP)\n",
    "            \n",
    "        # Log tags\n",
    "#        mlflow.set_tag('Optimizer', 'Adam')\n",
    "#        mlflow.set_tag('Kernel size', 'Mixed')\n",
    "#        mlflow.set_tag('Skip connections', '4')\n",
    "#        mlflow.set_tag('Activation', 'Softplus')\n",
    "#        mlflow.set_tag('Mid Activation', 'Relu')\n",
    "        mlflow.set_tag('Asymmetry', '9.0')\n",
    "\n",
    "        # Save model state dictionary, optimizer state dictionary, and epoch number\n",
    "        torch.save({\n",
    "            'model':model.state_dict(),\n",
    "            'optimizer':optimizer.state_dict(),\n",
    "            'epoch':args.epochs+result['epoch']\n",
    "            }, 'run_stats.pyt')\n",
    "        # Save the run stats into mlflow\n",
    "        mlflow.log_artifact('run_stats.pyt')\n",
    "            \n",
    "        # Save a diagram of the architecture\n",
    "#        HL.transforms.Fold(\"Conv\", \"Conv\"),\n",
    "#        HL.build_graph(model, torch.zeros([args.batch_size, 1, 4000]).to(device)).save('architecture', format='png')\n",
    "#        mlflow.log_artifact('architecture.png')\n",
    "        \n",
    "        # log the code for the model architecture\n",
    "#        mlflow.log_artifact('architecture.txt')\n",
    "        \n",
    "    dual_train_plots(results.index,\n",
    "                 results.cost, results.val, \n",
    "                 results['eff_val'].apply(lambda x: x.eff_rate),\n",
    "                 results['eff_val'].apply(lambda x: x.fp_rate))\n",
    "    # save plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plot.png')\n",
    "    mlflow.log_artifact('plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goofit-june2020",
   "language": "python",
   "name": "goofit-june2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
