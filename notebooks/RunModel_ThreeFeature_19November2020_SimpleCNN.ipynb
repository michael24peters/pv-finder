{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%matplotlib widget\n",
    "## with %matplotlib notebook: seems to require ipympl as part of environment, either\n",
    "## part of the conda environment or \"pip install ipympl\"\n",
    "## otherwise, does not show ANY plots in notebook, plt.savefig() works\n",
    "%matplotlib notebook  \n",
    "##%matplotlib inline    ## --plt.savefig()  works, but re-sizing does NOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current GPU usage. Please try to be nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 11 21:25:33 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN V             Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 28%   31C    P8    23W / 250W |   9071MiB / 12066MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:83:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN V             Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 25%   36C    P0    34W / 250W |      0MiB / 12066MiB |      8%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     38386      C   ...a/conda/envs/goofit-june2020/bin/python  9059MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "# Python 3 standard library\n",
    "from pathlib import Path\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "'''\n",
    "HELPER FUNCTIONS\n",
    "'''\n",
    "# From model/collectdata.py\n",
    "from model.collectdata_mdsA import collect_data\n",
    "# new KDE (KDE_A)\n",
    "from model.collectdata_poca_KDE import collect_data_poca\n",
    "\n",
    "# From model/loss.py\n",
    "##from loss import Loss\n",
    "from model.alt_loss_A import Loss\n",
    "\n",
    "# From model/training.py\n",
    "from model.training import trainNet, select_gpu, Results\n",
    "\n",
    "# From model/models.py\n",
    "##  will start with model from TwoFeatures_CNN6Layer_A in the first instance\n",
    "##  see relevant cell below\n",
    "\n",
    "from model.models_mjp_19November20 import SimpleCNN5Layer_Ca_A as ModelA\n",
    "from model.models_mjp_19November20 import SimpleCNN5Layer_Ca_E as ModelE\n",
    "from model.models_mjp_19November20 import SimpleCNN7Layer_Ca_W as ModelW\n",
    "from model.models_mjp_26December20 import SimpleCNN9Layer_Ca_X as ModelX\n",
    "from model.models_mjp_26December20 import SimpleCNN7Layer_Ca_Y as ModelY\n",
    "from model.models_mjp_30Jan21_AllCNN import ACN_1_10L_4S as ModelXX\n",
    "\n",
    "# From model/utilities.py\n",
    "from model.utilities import load_full_state, count_parameters, Params\n",
    "\n",
    "from model.plots import dual_train_plots, replace_in_ax\n",
    "\n",
    "## adds image of model architecture\n",
    "import hiddenlayer as HL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Torch device configuration. All tensors and model parameters need to know where to be put.\n",
    "This takes a BUS ID number: The BUS ID is the same as the listing at the top of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 available GPUs (initially using device 0):\n",
      "  0 TITAN V\n"
     ]
    }
   ],
   "source": [
    "device = select_gpu(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params order - batch size, epochs, lr, epoch_start (which is usually set to 0)\n",
    "## Use a learning rate of 5e-5 for 20 epochs if this is the first step of the model.\n",
    "##  This is done to break the initial \"stalling\" of a model. After that, switch to \n",
    "##  1e-3 for about 200 epochs\n",
    "args = Params(128, 20, 5e-5, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the dataset, split into parts, then move to device (see `collectdata.py` in the `../model` directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded /share/lazy/will/data/June30_2020_80k_1.h5 in 16.97 s\n",
      "Constructing 80000 event dataset took 3.332 s\n",
      "Loading data...\n",
      "Loaded dataAA/20K_POCA_kernel_evts_200926.h5 in 0.0207 s\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'dataAA/20K_POCA_kernel_evts_200926.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3f92182e1dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                             \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                             \u001b[0;31m##slice = slice(18000,None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                            )\n",
      "\u001b[0;32m~/pv-finder_experimental/notebooks/model/collectdata_poca_KDE.py\u001b[0m in \u001b[0;36mcollect_data_poca\u001b[0;34m(batch_size, dtype, device, masking, slice, load_xy, load_A_and_B, load_XandXsq, *files, **kargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mXY_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Loaded {XY_file} in {{time:.4}} s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXY_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mXY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;31m## [:,np.newaxis,:] makes X (a x b) --> (a x 1 x b) (axis 0, axis 1, axis 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m## a is *probably* 4000 and b is *probably* N, but it could be the other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'dataAA/20K_POCA_kernel_evts_200926.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "## newer vernacular\n",
    "## Training dataset. You can put as many files here as desired.\n",
    "\n",
    "## Using a smaller training set reduces both the time to load the data and the time to train an epoch\n",
    "##  set the option load_XandXsq = True to use both DKE and KDE^2 as input features.\n",
    "## This is for the original KDE.\n",
    "##  and load_xy=False).\n",
    "'''\n",
    "train_loader = collect_data('/share/lazy/sokoloff/ML-data_A/Aug14_80K_train.h5',\n",
    "                             '/share/lazy/sokoloff/ML-data_AA/Oct03_80K_train.h5',\n",
    "#                             '/share/lazy/sokoloff/ML-data_AA/Oct03_40K_train.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_1.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_3.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_4.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_5.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_6.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_7.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_8.h5',\n",
    "#                             '/share/lazy/will/ML_mdsA/June30_2020_80k_9.h5',\n",
    "                            #'/share/lazy/sokoloff/ML-data_AA/Oct03_80K2_train.h5',\n",
    "                             batch_size=args.batch_size,\n",
    "## if we are using a larger dataset (240K events, with the datasets above, and 11 GB  of GPU memory),\n",
    "## not the dataset will overflow the GPU memory; device=device will allow the data to move back\n",
    "## and forth between the CPU and GPU memory. While this allows use of a larger dataset, it slows\n",
    "## down performance by about 10%.  So comment out when not needed.\n",
    "                            device=device,\n",
    "                            masking=True, shuffle=True,\n",
    "                            load_XandXsq=False,\n",
    "                            load_xy=False)\n",
    "'''\n",
    "\n",
    "# Validation dataset. You can slice to reduce the size.\n",
    "## dataAA -> /share/lazy/sokoloff/ML-data_AA/\n",
    "## This is for the original KDE.\n",
    "'''\n",
    "val_loader = collect_data('/share/lazy/sokoloff/ML-data_AA/Oct03_20K_val.h5',\n",
    "                          batch_size=args.batch_size,\n",
    "                          slice=slice(256 * 39),\n",
    "                          device=device,\n",
    "                          masking=True, shuffle=False,\n",
    "                          load_XandXsq=False,\n",
    "                          load_xy=False)\n",
    "'''\n",
    "\n",
    "## This is for the new KDE (KDE_A)\n",
    "train_loader = collect_data_poca('/share/lazy/will/data/June30_2020_80k_1.h5',\n",
    "                            batch_size=args.batch_size,\n",
    "                            device=device,\n",
    "                            masking=True, shuffle=True,\n",
    "                           ## slice = slice(0,18000)\n",
    "                           )\n",
    "\n",
    "val_loader = collect_data_poca('dataAA/20K_POCA_kernel_evts_200926.h5',\n",
    "                            batch_size=args.batch_size,\n",
    "                            device=device,\n",
    "                            masking=True, shuffle=True,\n",
    "                            ##slice = slice(18000,None)\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a model, use multiple GPUs if they are VISIBLE, and move the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ModelXX()\n",
    "\n",
    "##summary(model, input_size=(4, 4000))\n",
    "##print(model.parameters)\n",
    "\n",
    "mlflow.tracking.set_tracking_uri('file:/share/lazy/pv-finder_model_repo')\n",
    "mlflow.set_experiment('Four Feature AllCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = Loss(epsilon=1e-5,coefficient=2.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "##  use the first five layers from a pre-existing model\n",
    "##  see example at https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113\n",
    "##   ML -> /share/lazy/sokoloff/ML\n",
    "\n",
    "# don't need this; likely relic code (keep for now)\n",
    "#path = 'run_stats.pyt'\n",
    "#load_full_state(model, optimizer, path)\n",
    "\n",
    "# When loading pretrained models, use this code; otherwise, comment it out\n",
    "# For other pretrained models, go to MLFlow and find the path for \"run_stats.pyt\"\n",
    "#pretrained_dict = '/share/lazy/pv-finder_model_repo/12/3bdf391886824901b0172ceff25d948e/artifacts/run_stats.pyt'\n",
    "#load_full_state(model, optimizer, pretrained_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \n",
    "\n",
    "\n",
    "\n",
    "The body of this loop runs once per epoch. Results is a named tuple of values (loss per epoch for training and validation, time each). Start by setting up a plot first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, tax, lax, lines = dual_train_plots()\n",
    "fig = ax.figure\n",
    "plt.tight_layout()\n",
    "# This gets built up during the run - do not rerun this cell\n",
    "results = pd.DataFrame([], columns=Results._fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avgEff = 0.0\n",
    "avgFP = 0.0\n",
    "print('for model: ', model)   \n",
    "run_name = 'ACN_1_10L_4S (P1)'\n",
    "# Create an mlflow run\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters of the model\n",
    "    for key, value in vars(args).items():\n",
    "        print(key, value)\n",
    "        mlflow.log_param(key, value)\n",
    "    \n",
    "    # Log parameter count in the model\n",
    "    mlflow.log_param('Parameters', count_parameters(model))\n",
    "    \n",
    "    # Begin run\n",
    "    for result in trainNet(model, optimizer, loss,\n",
    "                            train_loader, val_loader,\n",
    "                            args.epochs+args.epoch_start, epoch_start=args.epoch_start,\n",
    "                            notebook=True, device=device):\n",
    "\n",
    "        result = result._asdict()\n",
    "        results = results.append(pd.Series(result), ignore_index=True)\n",
    "        xs = results.index\n",
    "\n",
    "        # Update the plot above\n",
    "        lines['train'].set_data(results.index, results.cost)\n",
    "        lines['val'].set_data(results.index, results.val)\n",
    "\n",
    "        #filter first cost epoch (can be really large)\n",
    "        max_cost = max(max(results.cost if len(results.cost)<2 else results.cost[1:]), max(results.val))\n",
    "        min_cost = min(min(results.cost), min(results.val))\n",
    "    \n",
    "        # The plot limits need updating too\n",
    "        ax.set_ylim(min_cost*.9, max_cost*1.1)  \n",
    "        ax.set_xlim(-.5, len(results.cost) - .5)\n",
    "    \n",
    "        replace_in_ax(lax, lines['eff'], xs, results['eff_val'].apply(lambda x: x.eff_rate))\n",
    "        replace_in_ax(tax, lines['fp'], xs, results['eff_val'].apply(lambda x: x.fp_rate))            \n",
    "            \n",
    "        # Redraw the figure\n",
    "        fig.canvas.draw()\n",
    "            \n",
    "        ## MLFLOW ##\n",
    "        # Log metrics\n",
    "        mlflow.log_metric('Efficiency', result['eff_val'].eff_rate, result['epoch'])\n",
    "        mlflow.log_metric('False Positive Rate',  result['eff_val'].fp_rate, result['epoch'])\n",
    "        mlflow.log_metric('Validation Loss',  result['val'], result['epoch'])\n",
    "        mlflow.log_metric('Training Loss',  result['cost'], result['epoch'])\n",
    "        \n",
    "        print('Result epoch: ', result['epoch'])\n",
    "        if(result['epoch'] >= args.epochs + args.epoch_start - 10):\n",
    "            avgEff += result['eff_val'].eff_rate\n",
    "            avgFP += result['eff_val'].fp_rate\n",
    "           \n",
    "        if(result['epoch'] == args.epochs + args.epoch_start - 1):\n",
    "            print('Averaging...\\n')\n",
    "            avgEff /= 10\n",
    "            avgFP /= 10\n",
    "            mlflow.log_metric('10 Efficiency Average', avgEff)\n",
    "            mlflow.log_metric('10 False Positive Average', avgFP)\n",
    "            \n",
    "        print('Average Eff: ', avgEff)\n",
    "        print('Average FP Rate: ', avgFP)\n",
    "        \n",
    "        # Log tags\n",
    "#        mlflow.set_tag('Optimizer', 'Adam')\n",
    "#        mlflow.set_tag('Kernel size', 'Mixed')\n",
    "#        mlflow.set_tag('Skip connections', '4')\n",
    "#        mlflow.set_tag('Activation', 'Softplus')\n",
    "#        mlflow.set_tag('Mid Activation', 'Relu')\n",
    "        mlflow.set_tag('Asymmetry', '2.5')\n",
    "        mlflow.set_tag('KDE', 'Poca')\n",
    "        mlflow.set_tag('Data', '80k')\n",
    "\n",
    "        # Save model state dictionary, optimizer state dictionary, and epoch number\n",
    "        torch.save({\n",
    "            'model':model.state_dict(),\n",
    "            'optimizer':optimizer.state_dict(),\n",
    "            'epoch':args.epochs+result['epoch']\n",
    "            }, 'run_stats.pyt')\n",
    "        # Save the run stats into mlflow\n",
    "        mlflow.log_artifact('run_stats.pyt')\n",
    "        \n",
    "    dual_train_plots(results.index,\n",
    "                 results.cost, results.val, \n",
    "                 results['eff_val'].apply(lambda x: x.eff_rate),\n",
    "                 results['eff_val'].apply(lambda x: x.fp_rate))\n",
    "    plt.tight_layout()\n",
    "    # save plot\n",
    "    plt.savefig('plot.png')  \n",
    "    mlflow.log_artifact('plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##quit()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "goofit-june2020",
   "language": "python",
   "name": "goofit-june2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
