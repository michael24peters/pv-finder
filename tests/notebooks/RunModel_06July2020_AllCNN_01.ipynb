{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%matplotlib widget\n",
    "## with %matplotlib notebook: seems to require ipympl as part of environment, either\n",
    "## part of the conda environment or \"pip install ipympl\"\n",
    "## otherwise, does not show ANY plots in notebook, plt.savefig() works\n",
    "%matplotlib notebook  \n",
    "##%matplotlib inline    ## --plt.savefig()  works, but re-sizing does NOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a short demo to illustrate execution.   For odd historical reasons, it uses \"toy Monte Carlo\" (simulated data)for \"training\" and \"full LHCB MC\" for validation.\n",
    "\n",
    "The network architecture is a \"simple\" model that uses 1 input channel (the KDE [kernel density estimator] but from the track parameters) feeding 5 convolutional layers followed by a fully connected layer.\n",
    "\n",
    "In today's version, the network will start with weights from a previously trained version.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current GPU usage. Please try to be nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  7 15:29:55 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN V             Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 28%   32C    P8    23W / 250W |   6387MiB / 12066MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:83:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    27W / 250W |     10MiB / 16280MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  TITAN V             Off  | 00000000:84:00.0 Off |                  N/A |\r\n",
      "| 34%   45C    P2    41W / 250W |   3969MiB / 12066MiB |     48%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     16714      C   ...a/conda/envs/goofit-june2020/bin/python  6375MiB |\r\n",
      "|    2     31670      C   ../../build/christoph_model/FinalFit1       3957MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WARNING**: The card numbers here are *not* the same as in CUDA. You have been warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "# Python 3 standard library\n",
    "from pathlib import Path\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "'''\n",
    "HELPER FUNCTIONS\n",
    "'''\n",
    "# From model/collectdata.py\n",
    "from model.collectdata_mdsA import collect_data\n",
    "\n",
    "# From model/loss.py\n",
    "##from loss import Loss\n",
    "from model.alt_loss_A import Loss\n",
    "\n",
    "# From model/training.py\n",
    "from model.training import trainNet, select_gpu, Results\n",
    "\n",
    "# From model/models.py\n",
    "##  will start with model from TwoFeatures_CNN6Layer_A in the first instance\n",
    "##  see relevant cell below\n",
    "\n",
    "from model.models_mds_07July2020 import All_CNN6Layer_A as ModelA\n",
    "from model.models_mds_07July2020 import All_CNN6Layer_B as ModelB\n",
    "from model.models_mds_07July2020 import All_CNN6Layer_C as ModelC\n",
    "from model.models_mds_07July2020 import All_CNN6Layer_D as ModelD\n",
    "from model.models_mds_07July2020 import All_CNN6Layer_E as ModelE\n",
    "\n",
    "# From model/utilities.py\n",
    "from model.utilities import load_full_state, count_parameters, Params\n",
    "\n",
    "from model.plots import dual_train_plots, replace_in_ax\n",
    "\n",
    "## adds image of model architecture\n",
    "import hiddenlayer as HL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Torch device configuration. All tensors and model parameters need to know where to be put.\n",
    "This takes a BUS ID number: The BUS ID is the same as the listing at the top of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 available GPUs (initially using device 0):\n",
      "  0 TITAN V\n"
     ]
    }
   ],
   "source": [
    "device = select_gpu(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the dataset, split into parts, then move to device (see `collectdata.py` in the `../model` directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded /share/lazy/sokoloff/ML-data_AA/Aug14_80K_train.h5 in 12.75 s\n",
      "Loaded /share/lazy/sokoloff/ML-data_AA/Oct03_80K_train.h5 in 11.21 s\n",
      "Constructing 160000 event dataset took 4.69 s\n",
      "Loading data...\n",
      "Loaded /share/lazy/sokoloff/ML-data_AA/Oct03_20K_val.h5 in 2.852 s\n",
      "Constructing 9984 event dataset took 0.08995 s\n"
     ]
    }
   ],
   "source": [
    "## newer vernacular\n",
    "## Training dataset. You can put as many files here as desired.\n",
    "\n",
    "## in this DEMO example we use only one 80K training set -- the model starts with well-trained weights,\n",
    "## and using a smaller training set reduces both the time to load the data and the time to train an epoch\n",
    "##  set the option load_XandXsq = True to use both DKE and KDE^2 as input features\n",
    "train_loader = collect_data('/share/lazy/sokoloff/ML-data_AA/Aug14_80K_train.h5',\n",
    "                            '/share/lazy/sokoloff/ML-data_AA/Oct03_80K_train.h5',\n",
    "                            #'/share/lazy/sokoloff/ML-data_AA/Oct03_80K2_train.h5',\n",
    "                             batch_size=128,\n",
    "## if we are using a larger dataset (240K events, with the datasets above, and 11 GB  of GPU memory),\n",
    "## not the dataset will overflow the GPU memory; device=device will allow the data to move back\n",
    "## and forth between the CPU and GPU memory. While this allows use of a larger dataset, it slows\n",
    "## down performance by about 10%.  So comment out when not needed.\n",
    "                            device=device,\n",
    "                            masking=True, shuffle=True,\n",
    "                            load_XandXsq=False,\n",
    "                            load_xy=False)\n",
    "\n",
    "# Validation dataset. You can slice to reduce the size.\n",
    "## dataAA -> /share/lazy/sokoloff/ML-data_AA/\n",
    "val_loader = collect_data('/share/lazy/sokoloff/ML-data_AA/Oct03_20K_val.h5',\n",
    "## mds val_loader = collect_data('dataAA/HLT1CPU_1kevts_val.h5',\n",
    "\n",
    "                          batch_size=128,\n",
    "                          slice=slice(256 * 39),\n",
    "                          device=device,\n",
    "                          masking=True, shuffle=False,\n",
    "                          load_XandXsq=False,\n",
    "                          load_xy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name is the output file name\n",
    "##  190810  mds\n",
    "folder = '02July2020_AllCNN_01'\n",
    "name = '02July2020_AllCNN_01'\n",
    "\n",
    "# Make an output folder named \"name\" (change if you want)\n",
    "\n",
    "## Special instructions for those working on goofy at UC\n",
    "## Please be very careful to make sure that your folder\n",
    "## does not live in a subdirectory of your home directory\n",
    "## this disk has very little capacity. Instead, use \n",
    "## a subdirectory in /share/lazy with a symbolic link to\n",
    "## it in this (the notebooks) subdirectory\n",
    "folder = '/share/lazy/pv-finder_model_repo/ML/' + folder\n",
    "output = Path(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the output directory if it does not exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a model, use multiple GPUs if they are VISIBLE, and move the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'ML'. Detailed error Yaml file '/share/lazy/pv-finder_model_repo/ML/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/michael24peters/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 197, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/michael24peters/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 260, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/michael24peters/.local/lib/python3.7/site-packages/mlflow/utils/file_utils.py\", line 167, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/share/lazy/pv-finder_model_repo/ML/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct, child =  0    Conv1d(1, 20, kernel_size=(25,), stride=(1,), padding=(12,))\n",
      "ct, child =  1    Conv1d(20, 10, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  2    Conv1d(10, 10, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  3    Conv1d(10, 10, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  4    Conv1d(10, 1, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "ct, child =  5    Conv1d(1, 1, kernel_size=(91,), stride=(1,), padding=(45,))\n",
      "ct, child =  6    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  7    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  8    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  9    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  10    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  0    Conv1d(1, 16, kernel_size=(25,), stride=(1,), padding=(12,))\n",
      "ct, child =  1    Conv1d(16, 9, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  2    Conv1d(9, 9, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  3    Conv1d(9, 9, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  4    Conv1d(9, 1, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "ct, child =  5    Conv1d(1, 1, kernel_size=(91,), stride=(1,), padding=(45,))\n",
      "ct, child =  6    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  7    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  8    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  9    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  10    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  0    Conv1d(1, 20, kernel_size=(25,), stride=(1,), padding=(12,))\n",
      "ct, child =  1    Conv1d(20, 10, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  2    Conv1d(30, 10, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  3    Conv1d(10, 10, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  4    Conv1d(10, 1, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "ct, child =  5    Conv1d(1, 1, kernel_size=(91,), stride=(1,), padding=(45,))\n",
      "ct, child =  6    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  7    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  8    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  9    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  10    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  0    Conv1d(1, 20, kernel_size=(25,), stride=(1,), padding=(12,))\n",
      "ct, child =  1    Conv1d(20, 10, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  2    Conv1d(10, 10, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  3    Conv1d(10, 10, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  4    Conv1d(10, 1, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "ct, child =  5    Conv1d(1, 1, kernel_size=(91,), stride=(1,), padding=(45,))\n",
      "ct, child =  6    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  7    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  8    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  9    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  10    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  11    BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ct, child =  12    BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ct, child =  13    BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ct, child =  14    BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ct, child =  15    BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ct, child =  0    Conv1d(1, 16, kernel_size=(25,), stride=(1,), padding=(12,))\n",
      "ct, child =  1    Conv1d(16, 9, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  2    Conv1d(25, 9, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  3    Conv1d(9, 9, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  4    Conv1d(9, 1, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "ct, child =  5    Conv1d(1, 1, kernel_size=(91,), stride=(1,), padding=(45,))\n",
      "ct, child =  6    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  7    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  8    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  9    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  10    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  11    BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ct, child =  12    BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ct, child =  13    BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ct, child =  14    BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ct, child =  15    BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    }
   ],
   "source": [
    "model = ModelA()\n",
    "\n",
    "##summary(model, input_size=(4, 4000))\n",
    "##print(model.parameters)\n",
    "\n",
    "mlflow.tracking.set_tracking_uri('file:/share/lazy/pv-finder_model_repo')\n",
    "mlflow.set_experiment('ALLCNN')\n",
    "\n",
    "## add the following code to allow the user to freeze the some of the weights corresponding \n",
    "## to those taken from an earlier model trained with the original target histograms\n",
    "## presumably -- this leaves either the perturbative filter \"fixed\" and lets the \n",
    "## learning focus on the non-perturbative features, so get started faster, or vice versa\n",
    "# model\n",
    "ct = 0\n",
    "for child in model.children():\n",
    "    print('ct, child = ',ct, \"  \", child)\n",
    "    if ct < 0:\n",
    "        print(\"     About to set param.requires_grad=False for ct = \", ct, \"params\")\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False \n",
    "    ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the model's weight matricies to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output =  /share/lazy/pv-finder_model_repo/ML/02July2020_AllCNN_01\n",
      "for model_dict\n",
      "index, k =   0    conv1.weight\n",
      "index, k =   1    conv1.bias\n",
      "index, k =   2    conv2.weight\n",
      "index, k =   3    conv2.bias\n",
      "index, k =   4    conv3.weight\n",
      "index, k =   5    conv3.bias\n",
      "index, k =   6    conv4.weight\n",
      "index, k =   7    conv4.bias\n",
      "index, k =   8    conv5.weight\n",
      "index, k =   9    conv5.bias\n",
      "index, k =   10    finalFilter.weight\n",
      "index, k =   11    finalFilter.bias\n",
      " \n",
      "   for pretrained_dict\n",
      "index, k =   0    conv1.weight\n",
      "index, k =   1    conv1.bias\n",
      "index, k =   2    conv2.weight\n",
      "index, k =   3    conv2.bias\n",
      "index, k =   4    conv3.weight\n",
      "index, k =   5    conv3.bias\n",
      "index, k =   6    conv4.weight\n",
      "index, k =   7    conv4.bias\n",
      "index, k =   8    conv5.weight\n",
      "index, k =   9    conv5.bias\n",
      "index, k =   10    finalFilter.weight\n",
      "index, k =   11    finalFilter.bias\n",
      "model_dict instantiated\n",
      " \n",
      "   for 'reduced' pretrained_dict\n",
      "index, k =   0    conv1.weight\n",
      "index, k =   1    conv1.bias\n",
      "index, k =   2    conv2.weight\n",
      "index, k =   3    conv2.bias\n",
      "index, k =   4    conv3.weight\n",
      "index, k =   5    conv3.bias\n",
      "index, k =   6    conv4.weight\n",
      "index, k =   7    conv4.bias\n",
      "index, k =   8    conv5.weight\n",
      "index, k =   9    conv5.bias\n",
      "index, k =   10    finalFilter.weight\n",
      "index, k =   11    finalFilter.bias\n",
      "pretrained_dict iterated\n",
      "model_dict updated\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for All_CNN6Layer_B:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([20, 1, 25]) from checkpoint, the shape in current model is torch.Size([16, 1, 25]).\n\tsize mismatch for conv1.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for conv2.weight: copying a param with shape torch.Size([10, 20, 15]) from checkpoint, the shape in current model is torch.Size([9, 16, 15]).\n\tsize mismatch for conv2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([9]).\n\tsize mismatch for conv3.weight: copying a param with shape torch.Size([10, 10, 15]) from checkpoint, the shape in current model is torch.Size([9, 9, 15]).\n\tsize mismatch for conv3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([9]).\n\tsize mismatch for conv4.weight: copying a param with shape torch.Size([10, 10, 15]) from checkpoint, the shape in current model is torch.Size([9, 9, 15]).\n\tsize mismatch for conv4.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([9]).\n\tsize mismatch for conv5.weight: copying a param with shape torch.Size([1, 10, 5]) from checkpoint, the shape in current model is torch.Size([1, 9, 5]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1e1bd54973e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mpretrained_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpretrained_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodelb_dict\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mmodelb_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mmodel_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mmodelc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for All_CNN6Layer_B:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([20, 1, 25]) from checkpoint, the shape in current model is torch.Size([16, 1, 25]).\n\tsize mismatch for conv1.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for conv2.weight: copying a param with shape torch.Size([10, 20, 15]) from checkpoint, the shape in current model is torch.Size([9, 16, 15]).\n\tsize mismatch for conv2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([9]).\n\tsize mismatch for conv3.weight: copying a param with shape torch.Size([10, 10, 15]) from checkpoint, the shape in current model is torch.Size([9, 9, 15]).\n\tsize mismatch for conv3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([9]).\n\tsize mismatch for conv4.weight: copying a param with shape torch.Size([10, 10, 15]) from checkpoint, the shape in current model is torch.Size([9, 9, 15]).\n\tsize mismatch for conv4.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([9]).\n\tsize mismatch for conv5.weight: copying a param with shape torch.Size([1, 10, 5]) from checkpoint, the shape in current model is torch.Size([1, 9, 5])."
     ]
    }
   ],
   "source": [
    "print('output = ',output)\n",
    "\n",
    "##  use the first five layers from a pre-existing model\n",
    "##  see example at https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113\n",
    "\n",
    "##   ML -> /share/lazy/sokoloff/ML\n",
    "pretrained_dict = torch.load('/share/lazy/pv-finder_model_repo/ML/02July2020_From_SimpleCNN_toAllCNN_01/02July2020_From_SimpleCNN_toAllCNN_01_final.pyt')\n",
    "model_dict = model.state_dict()\n",
    "## mds 190725 for debugging\n",
    "print(\"for model_dict\")\n",
    "index = 0\n",
    "for k,v in model_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    "    \n",
    "print(\" \\n\",\"  for pretrained_dict\")\n",
    "index = 0\n",
    "for k,v in pretrained_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    "## mds  \n",
    "\n",
    "print(\"model_dict instantiated\")\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "\n",
    "print(\" \\n\",\"  for 'reduced' pretrained_dict\")\n",
    "index = 0\n",
    "for k,v in pretrained_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    "## mds  \n",
    "print(\"pretrained_dict iterated\")\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "print('model_dict updated')\n",
    "##print('model_dict =    ', model_dict)\n",
    "##\n",
    "#   when starting from a model with a fully connected last layer rather than a convolutional layer\n",
    "# 3. load the new state dict\n",
    "#   need to use strict=False as the two models state model attributes do not agree exactly\n",
    "#   see https://pytorch.org/docs/master/_modules/torch/nn/modules/module.html#Module.load_state_dict\n",
    "\n",
    "model.load_state_dict(model_dict,strict=False)\n",
    "\n",
    "## print('model_dict =    ', model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# params order - batch size, epochs, lr, epoch_start (which is usually set to 0)\n",
    "# creating runs allows for multiple runs to be run sequentially (sep. by commas)\n",
    "runs = [\n",
    "    (model.to(device), Params(128, 5, 1e-3, 19))\n",
    "]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \n",
    "\n",
    "\n",
    "\n",
    "The body of this loop runs once per epoch. Results is a named tuple of values (loss per epoch for training and validation, time each). Start by setting up a plot first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loop through models in runs dictionary\n",
    "for (model, args) in runs:\n",
    "    \n",
    "    ax, tax, lax, lines = dual_train_plots()\n",
    "    fig = ax.figure\n",
    "    plt.tight_layout()\n",
    "    # This gets built up during the run - do not rerun this cell\n",
    "    results = pd.DataFrame([], columns=Results._fields)\n",
    "    \n",
    "    print('for model: ', model)\n",
    "    ##  mds 200121 loss = Loss(epsilon=1e-5,coefficient=1.0)\n",
    "    loss = Loss(epsilon=1e-5,coefficient=2.5)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    run_name = 'ACNN'\n",
    "    # Create an mlflow run\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        # Log parameters of the model\n",
    "        for key, value in vars(args).items():\n",
    "            print(key, value)\n",
    "            mlflow.log_param(key, value)\n",
    "        \n",
    "        # Log parameter count in the model\n",
    "        mlflow.log_param('Parameters', count_parameters(model))\n",
    "        \n",
    "        # Begin run\n",
    "        for result in trainNet(model, optimizer, loss,\n",
    "                                train_loader, val_loader,\n",
    "                                args.epochs+args.epoch_start, epoch_start=args.epoch_start,\n",
    "                                notebook=True, device=device):\n",
    "    \n",
    "            result = result._asdict()\n",
    "            results = results.append(pd.Series(result), ignore_index=True)\n",
    "            xs = results.index\n",
    "    \n",
    "            # Update the plot above\n",
    "            lines['train'].set_data(results.index, results.cost)\n",
    "            lines['val'].set_data(results.index, results.val)\n",
    "    \n",
    "            #filter first cost epoch (can be really large)\n",
    "            max_cost = max(max(results.cost if len(results.cost)<2 else results.cost[1:]), max(results.val))\n",
    "            min_cost = min(min(results.cost), min(results.val))\n",
    "    \n",
    "            # The plot limits need updating too\n",
    "            ax.set_ylim(min_cost*.9, max_cost*1.1)  \n",
    "            ax.set_xlim(-.5, len(results.cost) - .5)\n",
    "    \n",
    "            replace_in_ax(lax, lines['eff'], xs, results['eff_val'].apply(lambda x: x.eff_rate))\n",
    "            replace_in_ax(tax, lines['fp'], xs, results['eff_val'].apply(lambda x: x.fp_rate))\n",
    "    \n",
    "            # Redraw the figure\n",
    "            fig.canvas.draw()\n",
    "            plt.tight_layout()\n",
    "            fig.savefig('plot.png')\n",
    "            \n",
    "            \n",
    "            ## MLFLOW ##\n",
    "            # Log metrics\n",
    "            mlflow.log_metric('Efficiency', result['eff_val'].eff_rate, result['epoch'])\n",
    "            mlflow.log_metric('False Positive Rate',  result['eff_val'].fp_rate, result['epoch'])\n",
    "            mlflow.log_metric('Validation Loss',  result['val'], result['epoch'])\n",
    "            mlflow.log_metric('Training Loss',  result['cost'], result['epoch'])\n",
    "            \n",
    "            # Log tags\n",
    "#            mlflow.set_tag('Optimizer', 'Adam')\n",
    "#            mlflow.set_tag('Kernel size', 'Mixed')\n",
    "#            mlflow.set_tag('Skip connections', '4')\n",
    "#            mlflow.set_tag('Activation', 'Softplus')\n",
    "#            mlflow.set_tag('Mid Activation', 'Relu')\n",
    "\n",
    "            # Save model state dictionary, optimizer state dictionary, and epoch number\n",
    "            torch.save({\n",
    "                'model':model.state_dict(),\n",
    "                'optimizer':optimizer.state_dict(),\n",
    "                'epoch':args.epochs+result['epoch']\n",
    "                }, 'run_stats.pyt')\n",
    "            # Save the run stats into mlflow\n",
    "            mlflow.log_artifact('run_stats.pyt')\n",
    "            \n",
    "            # Save a diagram of the architecture\n",
    "            HL.transforms.Fold(\"Conv\", \"Conv\"),\n",
    "            HL.build_graph(model, torch.zeros([args.batch_size, 1, 4000]).to(device)).save('architecture', format='png')\n",
    "            mlflow.log_artifact('architecture.png')\n",
    "        \n",
    "            # log the code for the model architecture\n",
    "#            mlflow.log_artifact('architecture.txt')\n",
    "        \n",
    "            # save plot\n",
    "            mlflow.log_artifact('plot.png')\n",
    "            \n",
    "            # Save each model state dictionary\n",
    "            torch.save(model.state_dict(), (output / f'{name}_{args.epochs}.pyt'))\n",
    "    \n",
    "    # Go ahead and save the final model (even though it was also saved above):\n",
    "    torch.save(model.state_dict(), output / f'{name}_final.pyt')\n",
    "    # Save the output results:\n",
    "    results.to_hdf(f'{name}_stats.hdf5', 'results')\n",
    "    \n",
    "    # Save the plot above:\n",
    "#    plt.tight_layout()\n",
    "#    plt.savefig(str(output / f'{name}_stats_a.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goofit-june2020",
   "language": "python",
   "name": "goofit-june2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
