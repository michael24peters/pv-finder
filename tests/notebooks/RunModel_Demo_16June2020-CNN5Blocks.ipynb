{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current GPU usage. Please try to be nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 24 10:48:53 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN V             Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 28%   31C    P8    23W / 250W |   1697MiB / 12066MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:83:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    27W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN V             Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 29%   43C    P2    40W / 250W |   3971MiB / 12066MiB |     38%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     16276      C   /data/conda/envs/goofit/bin/python          1685MiB |\n",
      "|    2     31175      C   ../../build/christoph_model/FinalFit1       3959MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WARNING**: The card numbers here are *not* the same as in CUDA. You have been warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import hiddenlayer as HL\n",
    "\n",
    "# Python 3 standard library\n",
    "from pathlib import Path\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the helper functions\n",
    "\n",
    "Add the directory with the model\n",
    "definitions to the path so we can import from it:\n",
    "\n",
    "> When you type `import X`,\n",
    "Python searches `sys.path` for a python\n",
    "file named `X.py` to import. So we need to add the model directory to the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# From model/collectdata.py\n",
    "from model.collectdata_mdsA import collect_data\n",
    "\n",
    "# From model/loss.py\n",
    "##from loss import Loss\n",
    "from model.alt_loss_A import Loss\n",
    "\n",
    "# From model/training.py\n",
    "from model.training import trainNet, select_gpu\n",
    "\n",
    "# From model/models.py\n",
    "##  will start with model from TwoFeatures_CNN6Layer_A in the first instance\n",
    "##  see relevant cell below\n",
    "\n",
    "## From model/utilities.py\n",
    "## from model.utilities import load_first_layer, load_full_state\n",
    "\n",
    "from model.model_16June2020 import CNN5Blocks as Model\n",
    "\n",
    "from model.training import trainNet, select_gpu, Results\n",
    "from model.plots import dual_train_plots, replace_in_ax\n",
    "\n",
    "from mlflow import pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params(object):\n",
    "    def __init__(self, batch_size, epochs, lr, epoch_start=0):\n",
    "        self.epoch_start = epoch_start\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        \n",
    "args = Params(64, 10, 0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Torch device configuration. All tensors and model parameters need to know where to be put.\n",
    "This takes a BUS ID number: The BUS ID is the same as the listing at the top of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 available GPUs (initially using device 0):\n",
      "  0 TITAN V\n"
     ]
    }
   ],
   "source": [
    "device = select_gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the dataset, split into parts, then move to device (see `collectdata.py` in the `../model` directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded /share/lazy/sokoloff/ML-data_AA/Aug14_80K_train.h5 in 15.23 s\n",
      "Loaded /share/lazy/sokoloff/ML-data_AA/Oct03_80K_train.h5 in 17.03 s\n",
      "Constructing 160000 event dataset took 0.4822 s\n",
      "Loading data...\n",
      "Loaded /share/lazy/sokoloff/ML-data_AA/Oct03_20K_val.h5 in 4.655 s\n",
      "Constructing 9984 event dataset took 6.156 s\n"
     ]
    }
   ],
   "source": [
    "## newer vernacular\n",
    "## Training dataset. You can put as many files here as desired.\n",
    "\n",
    "## in this DEMO example we use only one 80K training set -- the model starts with well-trained weights,\n",
    "## and using a smaller training set reduces both the time to load the data and the time to train an epoch\n",
    "##  set the option load_XandXsq = True to use both DKE and KDE^2 as input features\n",
    "train_loader = collect_data('/share/lazy/sokoloff/ML-data_AA/Aug14_80K_train.h5',\n",
    "                            '/share/lazy/sokoloff/ML-data_AA/Oct03_80K_train.h5',\n",
    "##                            'dataAA/Oct03_80K2_train.h5',\n",
    "                             batch_size=args.batch_size,\n",
    "## if we are using a larger dataset (240K events, with the datasets above, and 11 GB  of GPU memory),\n",
    "## not the dataset will overflow the GPU memory; device=device will allow the data to move back\n",
    "## and forth between the CPU and GPU memory. While this allows use of a larger dataset, it slows\n",
    "## down performance by about 10%.  So comment out when not needed.\n",
    "##                           device=device,\n",
    "                            masking=True, shuffle=True,\n",
    "                            load_XandXsq=False,\n",
    "                            load_xy=False)\n",
    "\n",
    "# Validation dataset. You can slice to reduce the size.\n",
    "## dataAA -> /share/lazy/sokoloff/ML-data_AA/\n",
    "val_loader = collect_data('/share/lazy/sokoloff/ML-data_AA/Oct03_20K_val.h5',\n",
    "## mds val_loader = collect_data('dataAA/HLT1CPU_1kevts_val.h5',\n",
    "\n",
    "                          batch_size=args.batch_size,\n",
    "                          slice=slice(256 * 39),\n",
    "                          device=device,\n",
    "                          masking=True, shuffle=False,\n",
    "                          load_XandXsq=False,\n",
    "                          load_xy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a model, use multiple GPUs if they are VISIBLE, and move the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "##  mds 200121 loss = Loss(epsilon=1e-5,coefficient=1.0)\n",
    "loss = Loss(epsilon=1e-5,coefficient=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the model's weight matricies to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiment\n",
    "\n",
    "The first line sets the location to save the experiment. This will usually appear as a \"0\", \"1\", and so on (depending on how many experiments you have already created in the directory) in the specified folder. The next line sets the experiment name, which will be visible when launching MLFlow through localhost. This will be a piece of metadata and does not create a directory or file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlflow.tracking.set_tracking_uri('file:/share/lazy/pv-finder_model_repo')\n",
    "mlflow.set_experiment('CNN5Blocks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \n",
    "\n",
    "The first for loop saves the model and its corresponding data to the experiment so that it may be accessed in MLFlow.\n",
    "\n",
    "The body of this loop runs once per epoch. Results is a named tuple of values (loss per epoch for training and validation, time each). Log this data into the mlflow experiment set in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: train = 2500, val = 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael24peters/pv-finder/notebooks/model/training.py:94: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  file=sys.stderr,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a12c85541284081ba833e9b7544e061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epochs', layout=Layout(flex='2'), max=10.0, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=2500.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train=22.9473, val=21.3591, took 55.106 s\n",
      "  Validation Found 0 of 54504, added 0 (eff 0.00%) (0.0 FP/event)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=2500.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train=21.3351, val=21.3591, took 51.38 s\n",
      "  Validation Found 0 of 54504, added 0 (eff 0.00%) (0.0 FP/event)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=2500.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train=21.3351, val=21.3591, took 57.868 s\n",
      "  Validation Found 0 of 54504, added 0 (eff 0.00%) (0.0 FP/event)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=2500.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train=21.3351, val=21.3591, took 60.92 s\n",
      "  Validation Found 0 of 54504, added 0 (eff 0.00%) (0.0 FP/event)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=2500.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train=21.3351, val=21.3591, took 55.07 s\n",
      "  Validation Found 0 of 54504, added 0 (eff 0.00%) (0.0 FP/event)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=2500.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train=21.335, val=21.3591, took 53.132 s\n",
      "  Validation Found 0 of 54504, added 0 (eff 0.00%) (0.0 FP/event)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=2500.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train=21.335, val=21.3591, took 61.69 s\n",
      "  Validation Found 0 of 54504, added 0 (eff 0.00%) (0.0 FP/event)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=2500.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train=21.335, val=21.3591, took 60.259 s\n",
      "  Validation Found 0 of 54504, added 0 (eff 0.00%) (0.0 FP/event)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=2500.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train=21.335, val=21.3591, took 57.383 s\n",
      "  Validation Found 0 of 54504, added 0 (eff 0.00%) (0.0 FP/event)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=2500.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train=21.335, val=21.3591, took 54.612 s\n",
      "  Validation Found 0 of 54504, added 0 (eff 0.00%) (0.0 FP/event)\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4e7b0c81065d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# save a diagram of the architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mHL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Conv > LeakyRelu > Dropout\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ConvLReluDrop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mHL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'architecture'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'architecture.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/site-packages/hiddenlayer/graph.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, format)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# TODO: assert on acceptable format values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/site-packages/hiddenlayer/graph.py\u001b[0m in \u001b[0;36mbuild_dot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mGraphViz\u001b[0m \u001b[0mDigraph\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDigraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# Build GraphViz Digraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "model = Model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "we_are_training_from_scratch = True\n",
    "\n",
    "if not we_are_training_from_scratch:\n",
    "    # If we are not training from scratch, this path should be the path to the \"run_stats\" file in the artifacts \n",
    "    # directory of whatever run you are using as a baseline. \n",
    "    # You can find the path in the MLFlow UI. It should end in /artifacts/run_stats\n",
    "    PATH = '/share/lazy/pv-finder_model_repo/0/48ce52a07acd43ed8cf8316aff07aad9/artifacts/run_stats.pyt'\n",
    "    \n",
    "    epoch_start = load_full_state(model, optimizer, Path)\n",
    "\n",
    "run_name = 'Run 3'\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "\n",
    "    for key, value in vars(args).items():\n",
    "        mlflow.log_param(key, value)\n",
    "        \n",
    "    for result in trainNet(model, optimizer, loss,\n",
    "                            train_loader, val_loader,\n",
    "                            args.epochs+args.epoch_start, epoch_start=args.epoch_start,\n",
    "                            notebook=True):\n",
    "\n",
    "        # Log metrics\n",
    "        result = result._asdict()\n",
    "        mlflow.log_metric('Efficiency', result['eff_val'].eff_rate, result['epoch'])\n",
    "        mlflow.log_metric('False Positive Rate',  result['eff_val'].fp_rate, result['epoch'])\n",
    "        mlflow.log_metric('Validation Loss', result['val'], result['epoch'])\n",
    "        mlflow.log_metric('Training Loss',  float(result['cost']), int(result['epoch']))\n",
    "\n",
    "    # Log tags\n",
    "    mlflow.set_tag('Optimizer', 'Adam')\n",
    "    mlflow.set_tag('Activation', 'ReLU')\n",
    "    if result['eff_val'].eff_rate <= 0.05:\n",
    "        mlflow.set_tag('Stalled', 'True')\n",
    "    else:\n",
    "        mlflow.set_tag('Stalled', 'False')\n",
    "\n",
    "    # Save model AND optimizer state_dict AND epoch number.\n",
    "    torch.save({\n",
    "        'model':model.state_dict(),\n",
    "        'optimizer':optimizer.state_dict(),\n",
    "        'epoch':args.epochs+result['epoch']\n",
    "        }, 'run_stats.pyt')\n",
    "    mlflow.log_artifact('run_stats.pyt')\n",
    "    \n",
    "    # save a diagram of the architecture\n",
    "    HL.transforms.Fold(\"Conv > LeakyRelu > Dropout\", \"ConvLReluDrop\"),\n",
    "    HL.build_graph(model, torch.zeros([args.batch_size, 1, 4000]).to(device)).save('architecture', format='png')\n",
    "    mlflow.log_artifact('architecture.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##quit()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "goofit-june2020",
   "language": "python",
   "name": "goofit-june2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
