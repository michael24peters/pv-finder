{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current GPU usage. Please try to be nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 24 09:39:00 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN V             Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 28%   31C    P8    23W / 250W |   1697MiB / 12066MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:83:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    27W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN V             Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 29%   43C    P2    42W / 250W |   1841MiB / 12066MiB |     53%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     16276      C   /data/conda/envs/goofit/bin/python          1685MiB |\n",
      "|    2      5132      C   ../../build/christoph_model/FinalFit1       1829MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WARNING**: The card numbers here are *not* the same as in CUDA. You have been warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "# Python 3 standard library\n",
    "from pathlib import Path\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the helper functions\n",
    "\n",
    "Add the directory with the model\n",
    "definitions to the path so we can import from it:\n",
    "\n",
    "> When you type `import X`,\n",
    "Python searches `sys.path` for a python\n",
    "file named `X.py` to import. So we need to add the model directory to the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1abb371ff4de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# From model/collectdata.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectdata_mdsA\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollect_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# From model/loss.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m##from loss import Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pv-finder/notebooks/model/collectdata_mdsA.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mjagged\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pv-finder/notebooks/model/jagged.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaggedarrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/site-packages/awkward/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Numpy 1.13.1 or later required\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAwkwardArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChunkedArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAppendableArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndexedArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/site-packages/awkward/array/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/site-packages/awkward/persist.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/site-packages/awkward/type.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/data/conda/envs/goofit-june2020/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# From model/collectdata.py\n",
    "from model.collectdata_mdsA import collect_data\n",
    "\n",
    "# From model/loss.py\n",
    "##from loss import Loss\n",
    "from model.alt_loss_A import Loss\n",
    "\n",
    "# From model/training.py\n",
    "from model.training import trainNet, select_gpu\n",
    "\n",
    "# From model/models.py\n",
    "##  will start with model from TwoFeatures_CNN6Layer_A in the first instance\n",
    "##  see relevant cell below\n",
    "\n",
    "\n",
    "from model.models_mds_01June20 import SimpleCNN5Layer_Ca as Model\n",
    "\n",
    "from model.training import trainNet, select_gpu, Results\n",
    "from model.plots import dual_train_plots, replace_in_ax\n",
    "\n",
    "from mlflow import pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my model \n",
    "from torch import nn\n",
    "class Conv(nn.Module):\n",
    "    \"\"\"convolution => [BN] => Pooling => ReLU\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size = 7, padding = 3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride = 1, padding = padding),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=7, stride = 1, padding=3),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4))\n",
    "\n",
    "    def forward(self, x1):\n",
    "#         x1 = self.up(x1)\n",
    "        # skip connections\n",
    "        # diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        # diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        # x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "        #                 diffY // 2, diffY - diffY // 2])\n",
    "        # x = torch.cat([x2, x1], dim=1)\n",
    "        return self.up(x1)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = Conv(1, 25, kernel_size = 25, padding=12)\n",
    "        self.down1 = Conv(25, 64)\n",
    "        self.down2 = Conv(64, 64)\n",
    "        self.down3 = Conv(64, 64)\n",
    "        self.down4 = Conv(64, 64)\n",
    "        self.down5 = Conv(64, 64)\n",
    "        self.up1 = Up(64, 64)\n",
    "        self.up2 = Up(64, 64)\n",
    "        self.up3 = Up(64, 64)\n",
    "        self.up4 = Up(64, 64)\n",
    "        self.up5 = Up(64, 64)\n",
    "        self.outc = nn.Conv1d(64, 1, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         First_two = x[:, 0:2, :]  ## picks out the 0 & 1 feature sets, X & Xsq\n",
    "#         Second_two = x[:, 2:4, :]\n",
    "        x1 = self.inc(x) #First_two\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5)\n",
    "        x = self.up2(x)\n",
    "        x = self.up3(x)\n",
    "        x = self.up4(x)\n",
    "#         x = self.up5(torch.cat([x, x1[:,:, 1:2001]], 1))\n",
    "        x = self.up5(x)\n",
    "#         x = self.up5(x)\n",
    "        logits_x0 = self.outc(x)\n",
    "\n",
    "#         x1 = self.inc(Second_two)\n",
    "#         x2 = self.down1(x1)\n",
    "#         x3 = self.down2(x2)\n",
    "#         x4 = self.down3(x3)\n",
    "#         x5 = self.down4(x4)\n",
    "#         x = self.up1(x5)\n",
    "#         x = self.up2(x)\n",
    "#         x = self.up3(x)\n",
    "#         x = self.up4(x)\n",
    "#         x = self.up5(torch.cat([x, x1[:,:, 1:2001]], 1))\n",
    "# #         x = self.up5(x)\n",
    "#         logits_x1 = self.outc(x)\n",
    "\n",
    "#         ret = torch.nn.Softplus()(logits_x0 * logits_x1).reshape(128, 4000)\n",
    "        # Use this line for looking at summary() to understand shape and structure of U-net\n",
    "#        ret = torch.nn.Softplus()(logits_x0)\n",
    "        ret = torch.nn.Softplus()(logits_x0).reshape(64, 4000)\n",
    "        return  ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params(object):\n",
    "    def __init__(self, batch_size, epochs, lr):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        \n",
    "args = Params(128, 5, 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Torch device configuration. All tensors and model parameters need to know where to be put.\n",
    "This takes a BUS ID number: The BUS ID is the same as the listing at the top of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = select_gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the dataset, split into parts, then move to device (see `collectdata.py` in the `../model` directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## newer vernacular\n",
    "## Training dataset. You can put as many files here as desired.\n",
    "\n",
    "## in this DEMO example we use only one 80K training set -- the model starts with well-trained weights,\n",
    "## and using a smaller training set reduces both the time to load the data and the time to train an epoch\n",
    "##  set the option load_XandXsq = True to use both DKE and KDE^2 as input features\n",
    "train_loader = collect_data('/share/lazy/sokoloff/ML-data_AA/Aug14_80K_train.h5',\n",
    "                            '/share/lazy/sokoloff/ML-data_AA/Oct03_80K_train.h5',\n",
    "##                            'dataAA/Oct03_80K2_train.h5',\n",
    "                             batch_size=args.batch_size,\n",
    "## if we are using a larger dataset (240K events, with the datasets above, and 11 GB  of GPU memory),\n",
    "## not the dataset will overflow the GPU memory; device=device will allow the data to move back\n",
    "## and forth between the CPU and GPU memory. While this allows use of a larger dataset, it slows\n",
    "## down performance by about 10%.  So comment out when not needed.\n",
    "##                           device=device,\n",
    "                            masking=True, shuffle=True,\n",
    "                            load_XandXsq=False,\n",
    "                            load_xy=False)\n",
    "\n",
    "# Validation dataset. You can slice to reduce the size.\n",
    "## dataAA -> /share/lazy/sokoloff/ML-data_AA/\n",
    "val_loader = collect_data('/share/lazy/sokoloff/ML-data_AA/Oct03_20K_val.h5',\n",
    "## mds val_loader = collect_data('dataAA/HLT1CPU_1kevts_val.h5',\n",
    "\n",
    "                          batch_size=args.batch_size,\n",
    "                          slice=slice(256 * 39),\n",
    "                          device=device,\n",
    "                          masking=True, shuffle=False,\n",
    "                          load_XandXsq=False,\n",
    "                          load_xy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a model, use multiple GPUs if they are VISIBLE, and move the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "##  mds 200121 loss = Loss(epsilon=1e-5,coefficient=1.0)\n",
    "loss = Loss(epsilon=1e-5,coefficient=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the model's weight matricies to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = UNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiment\n",
    "\n",
    "The first line sets the location to save the experiment. This will usually appear as a \"0\", \"1\", and so on (depending on how many experiments you have already created in the directory) in the specified folder. The next line sets the experiment name, which will be visible when launching MLFlow through localhost. This will be a piece of metadata and does not create a directory or file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlflow.tracking.set_tracking_uri('file:/share/lazy/pv-finder_model_repo')\n",
    "mlflow.set_experiment('Weird U-Net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for looking at U-net architecture in terms of layer (type), output shape, and Param #\n",
    "#summary(UNet().to('cuda:0'), (1, 4000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \n",
    "\n",
    "The first for loop saves the model and its corresponding data to the experiment so that it may be accessed in MLFlow.\n",
    "\n",
    "The body of this loop runs once per epoch. Results is a named tuple of values (loss per epoch for training and validation, time each). Log this data into the mlflow experiment set in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "we_are_training_from_scratch = True\n",
    "\n",
    "if not we_are_training_from_scratch:\n",
    "    # If we are not training from scratch, this path should be the path to the \"run_stats\" file in the artifacts \n",
    "    # directory of whatever run you are using as a baseline. \n",
    "    # You can find the path in the MLFlow UI. It should end in /artifacts/run_stats\n",
    "    PATH = '/share/lazy/pv-finder_model_repo'\n",
    "    \n",
    "    # Load the model and optimizer state_dict, and the total number of epochs\n",
    "    # The use case for this is if we care about the optimizer state_dict, which we do if we have multiple training \n",
    "    # sessions with momentum and/or learning rate decay. this will track the decay/momentum.\n",
    "    checkpoint = torch.load(PATH)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    epoch_start = checkpoint['epoch']\n",
    "    \n",
    "    # do this so it does not use the learning rate from the previous run. this is unwanted behavior\n",
    "    # in our scenario since we are not using a learning rate scheduler, rather we want to tune the learning\n",
    "    # rate further after we have gotten past the stalling\n",
    "    checkpoint['optimizer']['param_groups'][0]['lr'] = args.lr\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "else:\n",
    "    epoch_start = 0\n",
    "\n",
    "run_name = 'Run 1'\n",
    "\n",
    "with mlflow.start_run(run_name = run_name) as run:\n",
    "# with mlflow.start_run() as run:\n",
    "\n",
    "    for key, value in vars(args).items():\n",
    "        mlflow.log_param(key, value)\n",
    "        mlflow.set_tag('Optimizer', 'Adam')\n",
    "        \n",
    "    for result in trainNet(model, optimizer, loss,\n",
    "                            train_loader, val_loader,\n",
    "                            args.epochs+epoch_start, epoch_start=epoch_start,\n",
    "                            notebook=True):\n",
    "\n",
    "        result = result._asdict()\n",
    "        mlflow.log_metric('Efficiency', result['eff_val'].eff_rate, result['epoch'])\n",
    "        mlflow.log_metric('False Positive Rate',  result['eff_val'].fp_rate, result['epoch'])\n",
    "        mlflow.log_metric('Validation Loss',  (2. * float(result['cost'])), int(result['epoch']))\n",
    "            \n",
    "        if result['eff_val'].eff_rate == 0:\n",
    "            mlflow.set_tag('Stalled', 'True')\n",
    "        else:\n",
    "            mlflow.set_tag('Stalled', 'False')\n",
    "\n",
    "    # Save model AND optimizer state_dict AND epoch number.\n",
    "    torch.save({\n",
    "        'model':model.state_dict(),\n",
    "        'optimizer':optimizer.state_dict(),\n",
    "        'epoch':args.epochs+result['epoch']\n",
    "        }, 'run_stats.pyt')\n",
    "    mlflow.log_artifact('run_stats.pyt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##quit()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "goofit-june2020",
   "language": "python",
   "name": "goofit-june2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
