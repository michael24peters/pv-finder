{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we grab matplotlib, and set the old \"classic\" style for some reason only Rui knows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the local imports. Make sure you import the correct model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from model.models import SimpleCNN4Layer_D35_sp as Model\n",
    "from model.models_mds_F import FourFeature_CNN6Layer_D as Model\n",
    "##from model.collectdata import collect_data, collect_truth\n",
    "from model.collectdata_mdsA import collect_data, collect_truth\n",
    "from model.training import select_gpu\n",
    "from model.plots_mdsA import plot_ruiplot\n",
    "from model.efficiency import pv_locations, efficiency\n",
    "from model.core import modernize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a GPU here. Same numbering as the NVidia-SMI tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = select_gpu(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a file to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = collect_data('dataAA/Oct03_20K_val.h5',\n",
    "                          batch_size=1,\n",
    "                          slice=slice(500),\n",
    "                          masking=True, shuffle=False,\n",
    "                          device=device,\n",
    "                          load_XandXsq=True,\n",
    "                          load_xy=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "XY_file = 'dataAA/Oct03_20K_val.h5'\n",
    "\n",
    "with h5py.File(XY_file, mode='r') as XY:\n",
    "    xmax = np.asarray(XY['Xmax'])\n",
    "    ymax = np.asarray(XY['Ymax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: to get the real PV locations, use `collect_truth('file.h5', pvs=True)` to collect PVs (or SVs with `pvs=False`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just see how many NaNs we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*np.sum(np.isnan(validation.dataset.tensors[1].cpu().numpy()), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV = collect_truth('dataAA/Oct03_20K_val.h5', pvs=True)\n",
    "print('PV.n.shape =    ',  PV.n.shape)\n",
    "print('PV.n[0].shape = ', *PV.n[0].shape)\n",
    "print('PV.x[0] =       ', *PV.x[0])\n",
    "print('PV.y[0] =       ', *PV.y[0])\n",
    "print('PV.z[0] =       ', *PV.z[0])\n",
    "print('PV.n[0] =       ', *PV.n[0])\n",
    "print('PV.cat[0] =     ', *PV.cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV.n.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV.cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV = collect_truth('dataAA/Oct03_20K_val.h5', pvs=False)\n",
    "print('SV.n.shape =    ', SV.n.shape)\n",
    "print('SV.n[0].shape = ', *SV.n[0].shape)\n",
    "print('SV.x[0] =       ', *SV.x[0])\n",
    "print('SV.y[0] =       ', *SV.y[0])\n",
    "print('SV.z[0] =       ', *SV.z[0])\n",
    "print('SV.n[0] =       ', *SV.n[0])\n",
    "print('SV.cat[0] =     ', *SV.cat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a model to load. Make sure it matches the model you imported above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Mike note:\n",
    ">\n",
    "> If you use an old-style model, comment out the `d = modernize(d, 3)` line - that converts the old model key names to the new format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = '/share/lazy/schreihf/PvFinder/models/Dec11_SimpleCNN4Layer_D35_sp_first200epochs_240K_lr_3em5_bs512_Alt_Loss_A_4p5_final.pyt'\n",
    "##name = '/home/sokoloff/pv-finder/notebooks/Dec21_SimpleCNN4Layer_D35_sp_yetAnother200epochs_240K_lr_1em3_bs512_Alt_Loss_A_4p5/Dec21_SimpleCNN4Layer_D35_sp_yetAnother200epochs_240K_lr_1em3_bs512_Alt_Loss_A_4p5_final.pyt'\n",
    "##name = '/home/sokoloff/pv-finder/notebooks/Dec21_SimpleCNN4Layer_D35_sp_yetAnother600epochs_240K_lr_3em4_bs512_Alt_Loss_A_4p5/Dec21_SimpleCNN4Layer_D35_sp_yetAnother600epochs_240K_lr_3em4_bs512_Alt_Loss_A_4p5_final.pyt'\n",
    "name = 'ML/Aug10_FourFeature_CNN6LayerPlus_TargetsA_First20epochs_160K_lr_1em3_bs64_Alt_Loss_A_3p0/Aug10_FourFeature_CNN6LayerPlus_TargetsA_First20epochs_160K_lr_1em3_bs64_Alt_Loss_A_3p0_final.pyt'\n",
    "name = 'ML/Aug11_FourFeature_CNN6LayerPlus_TargetsAA_First40epochs_fixedPert_160K_lr_1em3_bs64_Alt_Loss_A_3p0/Aug11_FourFeature_CNN6LayerPlus_TargetsAA_First40epochs_fixedPert__160K_lr_1em3_bs64_Alt_Loss_A_3p0_final.pyt'\n",
    "name = 'ML/Aug14_FourFeature_CNN6LayerPlus_TargetsAA_400epochs_160K_lr_3em4_bs64_Alt_Loss_A_3p0/Aug14_FourFeature_CNN6LayerPlus_TargetsAA_400epochs_160K_lr_3em4_bs64_Alt_Loss_A_3p0_399.pyt'\n",
    "name = 'ML/Aug16_FourFeature_CNN6LayerPlus_TargetsAA_YetAnother100epochs_160K_lr_1em4_bs128_Alt_Loss_A_4p5/Aug16_FourFeature_CNN6LayerPlus_TargetsAA_YetAnother100epochs_160K_lr_1em4_bs128_Alt_Loss_A_4p5_final.pyt'\n",
    "model = Model().to(device)\n",
    "d = torch.load(name)\n",
    "d = modernize(d, 3) # Only use if using the new Model definitions (should be safe if not, but unneccisary)\n",
    "model.load_state_dict(d)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab the outputs and labels as normal numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%time\n",
    "with torch.no_grad():\n",
    "    outputs = model(validation.dataset.tensors[0]).cpu().numpy()\n",
    "    labels = validation.dataset.tensors[1].cpu().numpy()\n",
    "## mds    print('outputs = ', outputs)\n",
    "## mds    print('labels = ',labels)\n",
    "\n",
    "## mds    print('outputs again = ', outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's Rui's plotting code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = validation.dataset.tensors[0].cpu().numpy()\n",
    "print('test.shape = ',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##print('validation.dataset.tensors = ',validation.dataset.tensors)\n",
    "\n",
    "\n",
    "inputs = validation.dataset.tensors[0].cpu().numpy()[:,0,:]\n",
    "##print(' = ',inputs)\n",
    "zvals = np.linspace(-100, 300, 4000, endpoint=False) + 0.05\n",
    "finalmsg = ''\n",
    "internal_count = 0\n",
    "output_filename = None # Or set: '120000_3layer_{number:02}.pdf'\n",
    "\n",
    "for event in range(100):\n",
    "    input = inputs[event]\n",
    "    label = labels[event]\n",
    "    output = outputs[event]\n",
    "    \n",
    "##    print('input from inputs = ',input)\n",
    "    \n",
    "    # Consistent parameters for the calls below\n",
    "    parameters = {\n",
    "        \"threshold\": 1e-2,\n",
    "        \"integral_threshold\": .2,\n",
    "        \"min_width\": 3\n",
    "    }\n",
    "    \n",
    "    # Compute the \"actual\" efficenies and things\n",
    "    ftruth = pv_locations(label, **parameters)\n",
    "    fcomputed = pv_locations(output, **parameters)\n",
    "    results = efficiency(label, output, difference=5.0, **parameters)\n",
    "    \n",
    "    # Add a line to the final results string (print at end)\n",
    "    finalmsg += f\"Event {event}: {results}\\n\"\n",
    "    \n",
    "    # Make sure bin numbers are integers\n",
    "    truth = np.around(ftruth).astype(np.int32)\n",
    "    computed = np.around(fcomputed).astype(np.int32)\n",
    "    \n",
    "    # Join arrays and remove any points closer than 5 bins\n",
    "    # We plot over these \"points of interest\"\n",
    "    poi = np.sort(np.concatenate([truth, computed]))\n",
    "    poi = poi[np.concatenate([[True], np.fabs(np.diff(poi)) > 5])]\n",
    "    \n",
    "    print(f\"\\nEvent {event}:\", results)\n",
    "    \n",
    "    for index, i in enumerate(poi):\n",
    "        # Convert to location in z\n",
    "        center = (i / 10) - 100\n",
    "        \n",
    "        # Collect items less than 5 apart as \"true\"\n",
    "        b_truth = np.fabs(ftruth - i) <= 5\n",
    "        b_comp = np.fabs(fcomputed - i) <= 5\n",
    "        in_truth = np.any(b_truth)\n",
    "        in_comp = np.any(b_comp)\n",
    "        \n",
    "        if in_truth and in_comp:\n",
    "            msg = 'PV found'\n",
    "        elif in_truth:\n",
    "            msg = 'PV not found'\n",
    "        elif False:\n",
    "            pass # Check for NaNs\n",
    "        else:\n",
    "            msg = 'False positive'\n",
    "            \n",
    "        with plt.style.context({\n",
    "            'font.size':18,\n",
    "            'font.weight':'bold'}):\n",
    "        \n",
    "            fig, axs = plt.subplots(2, figsize=(12,10), sharex=True,\n",
    "                                    gridspec_kw={'height_ratios':[2,1],\n",
    "                                                'hspace':0.1})\n",
    "        \n",
    "            # ax1 is the axis that is tied to left (density)\n",
    "            # ax2 is the axis that is tied to the right (probability)\n",
    "            ax1, ax2 = plot_ruiplot(zvals, i, input, label, output, ax=axs[0])\n",
    "            ax1.set_title(f\"Event {event} @ {center:.1f} mm: {msg}\",\n",
    "                          fontdict={'size':18, 'weight':'bold'})\n",
    "\n",
    "\n",
    "            msg = \"\"\n",
    "            \n",
    "            truth_centroid = (ftruth[b_truth] / 10) - 100\n",
    "            for value in truth_centroid:\n",
    "                msg += f\"True: {value:.3f} mm\\n\"\n",
    "                \n",
    "            comp_centroid = (fcomputed[b_comp] / 10) - 100\n",
    "            for value in comp_centroid:\n",
    "                msg += f\"Pred: {value:.3f} mm\\n\"\n",
    "                \n",
    "            if len(truth_centroid) == 1 and len(comp_centroid) == 1:\n",
    "                diff = (comp_centroid[0] - truth_centroid[0]) * 1_000\n",
    "                msg += f\"∆: {diff:.0f} µm\\n\"\n",
    "            \n",
    "            ax1.text(.02, .8, msg,\n",
    "                     transform=ax1.transAxes,\n",
    "                     verticalalignment='top')\n",
    "            \n",
    "            print(f\"\\nEvent {event}.{index}:\")\n",
    "            \n",
    "            # Plot and print PVs\n",
    "            ax2.scatter(PV.z[event], np.ones_like(PV.z[event])*.4, s=50, color='C0')\n",
    "            for x,y,z,n,cat in zip(PV.x[event], PV.y[event], PV.z[event], PV.n[event], PV.cat[event]):\n",
    "                # Only print out if z in plotting range\n",
    "                if center - 2.5 < z < center + 2.5:\n",
    "                    print()\n",
    "                    print(f'PV: {n} tracks (type {cat})')\n",
    "                    print(f'  x: {x*1000:5.0f} μm')\n",
    "                    print(f'  y: {y*1000:5.0f} μm')\n",
    "                    print(f'  z: {z:8.3f} mm')\n",
    "                    \n",
    "\n",
    "            # Plot and print SVs\n",
    "            ax2.scatter(SV.z[event], np.ones_like(SV.z[event])*.6, s=50, color='C1')\n",
    "            for x,y,z,n,cat in zip(SV.x[event], SV.y[event], SV.z[event], SV.n[event], SV.cat[event]):\n",
    "                # Only print out if z in plotting range\n",
    "                if center - 2.5 < z < center + 2.5:\n",
    "                    print()\n",
    "                    print(f'SV: {n} tracks (type {cat})')\n",
    "                    print(f'  x: {x*1000:5.0f} μm')\n",
    "                    print(f'  y: {y*1000:5.0f} μm')\n",
    "                    print(f'  z: {z:8.3f} mm')\n",
    "            \n",
    "            ax = axs[1]\n",
    "            ax.plot((np.arange(4000) / 10) - 100, xmax[event]*1000000, label=\"x\")\n",
    "            ax.plot((np.arange(4000) / 10) - 100, ymax[event]*1000000, label=\"y\")\n",
    "            ax.set_xlim(ax1.get_xlim())\n",
    "            ax.set_ylim(-150,150)\n",
    "            ax.grid(axis='y')\n",
    "            ax.set_ylabel('xy maximum [μm]')\n",
    "            ax.legend(loc='best')\n",
    "            \n",
    "            ax.set_xlabel(ax1.get_xlabel())\n",
    "            ax1.set_xlabel(\"\")\n",
    "            \n",
    "            # Save and show\n",
    "            if output_filename:        \n",
    "                plt.savefig(output_filename.format(number=internal_count))\n",
    "            plt.show()\n",
    "            \n",
    "            internal_count += 1\n",
    "            \n",
    "print(finalmsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
