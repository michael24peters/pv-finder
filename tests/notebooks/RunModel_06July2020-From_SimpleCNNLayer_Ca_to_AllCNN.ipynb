{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%matplotlib widget\n",
    "## with %matplotlib notebook: seems to require ipympl as part of environment, either\n",
    "## part of the conda environment or \"pip install ipympl\"\n",
    "## otherwise, does not show ANY plots in notebook, plt.savefig() works\n",
    "%matplotlib notebook  \n",
    "##%matplotlib inline    ## --plt.savefig()  works, but re-sizing does NOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a short demo to illustrate execution.   For odd historical reasons, it uses \"toy Monte Carlo\" (simulated data)for \"training\" and \"full LHCB MC\" for validation.\n",
    "\n",
    "The network architecture is a \"simple\" model that uses 1 input channel (the KDE [kernel density estimator] but from the track parameters) feeding 5 convolutional layers followed by a fully connected layer.\n",
    "\n",
    "In today's version, the network will start with weights from a previously trained version.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current GPU usage. Please try to be nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WARNING**: The card numbers here are *not* the same as in CUDA. You have been warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "# Python 3 standard library\n",
    "from pathlib import Path\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "'''\n",
    "HELPER FUNCTIONS\n",
    "'''\n",
    "# From model/collectdata.py\n",
    "from model.collectdata_mdsA import collect_data\n",
    "\n",
    "# From model/loss.py\n",
    "##from loss import Loss\n",
    "from model.alt_loss_A import Loss\n",
    "\n",
    "# From model/training.py\n",
    "from model.training import trainNet, select_gpu, Results\n",
    "\n",
    "# From model/models.py\n",
    "##  will start with model from TwoFeatures_CNN6Layer_A in the first instance\n",
    "##  see relevant cell below\n",
    "\n",
    "from model.models_mds_07July2020 import SimpleCNN5Layer_Ca as Model\n",
    "from model.models_mds_07July2020 import All_CNN6Layer_A as ModelA\n",
    "from model.models_mds_07July2020 import All_CNN6Layer_B as ModelB\n",
    "from model.models_mds_07July2020 import All_CNN6Layer_C as ModelC\n",
    "from model.models_mds_07July2020 import All_CNN6Layer_D as ModelD\n",
    "from model.models_mds_07July2020 import All_CNN6Layer_E as ModelE\n",
    "\n",
    "# From model/utilities.py\n",
    "from model.utilities import load_full_state, count_parameters, Params\n",
    "\n",
    "from model.plots import dual_train_plots, replace_in_ax\n",
    "\n",
    "## adds image of model architecture\n",
    "import hiddenlayer as HL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Torch device configuration. All tensors and model parameters need to know where to be put.\n",
    "This takes a BUS ID number: The BUS ID is the same as the listing at the top of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = select_gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params order - batch size, epochs, lr, epoch_start (which is usually set to 0)\n",
    "args = Params(128, 200, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the dataset, split into parts, then move to device (see `collectdata.py` in the `../model` directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## newer vernacular\n",
    "## Training dataset. You can put as many files here as desired.\n",
    "\n",
    "## in this DEMO example we use only one 80K training set -- the model starts with well-trained weights,\n",
    "## and using a smaller training set reduces both the time to load the data and the time to train an epoch\n",
    "##  set the option load_XandXsq = True to use both DKE and KDE^2 as input features\n",
    "train_loader = collect_data('/share/lazy/sokoloff/ML-data_AA/Aug14_80K_train.h5',\n",
    "                            '/share/lazy/sokoloff/ML-data_AA/Oct03_80K_train.h5',\n",
    "                            #'/share/lazy/sokoloff/ML-data_AA/Oct03_80K2_train.h5',\n",
    "                             batch_size=args.batch_size,\n",
    "## if we are using a larger dataset (240K events, with the datasets above, and 11 GB  of GPU memory),\n",
    "## not the dataset will overflow the GPU memory; device=device will allow the data to move back\n",
    "## and forth between the CPU and GPU memory. While this allows use of a larger dataset, it slows\n",
    "## down performance by about 10%.  So comment out when not needed.\n",
    "                            device=device,\n",
    "                            masking=True, shuffle=True,\n",
    "                            load_XandXsq=False,\n",
    "                            load_xy=False)\n",
    "\n",
    "# Validation dataset. You can slice to reduce the size.\n",
    "## dataAA -> /share/lazy/sokoloff/ML-data_AA/\n",
    "val_loader = collect_data('/share/lazy/sokoloff/ML-data_AA/Oct03_20K_val.h5',\n",
    "## mds val_loader = collect_data('dataAA/HLT1CPU_1kevts_val.h5',\n",
    "\n",
    "                          batch_size=args.batch_size,\n",
    "                          slice=slice(256 * 39),\n",
    "                          device=device,\n",
    "                          masking=True, shuffle=False,\n",
    "                          load_XandXsq=False,\n",
    "                          load_xy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a model, use multiple GPUs if they are VISIBLE, and move the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ModelC()\n",
    "\n",
    "##summary(model, input_size=(4, 4000))\n",
    "##print(model.parameters)\n",
    "\n",
    "mlflow.tracking.set_tracking_uri('file:/share/lazy/pv-finder_model_repo')\n",
    "mlflow.set_experiment('ALLCNN')\n",
    "\n",
    "## add the following code to allow the user to freeze the some of the weights corresponding \n",
    "## to those taken from an earlier model trained with the original target histograms\n",
    "## presumably -- this leaves either the perturbative filter \"fixed\" and lets the \n",
    "## learning focus on the non-perturbative features, so get started faster, or vice versa\n",
    "ct = 0\n",
    "for child in model.children():\n",
    "    print('ct, child = ',ct, \"  \", child)\n",
    "    if ct < 5:\n",
    "        print(\"     About to set param.requires_grad=False for ct = \", ct, \"params\")\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False \n",
    "    ct += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  mds 200121 loss = Loss(epsilon=1e-5,coefficient=1.0)\n",
    "loss = Loss(epsilon=1e-5,coefficient=2.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "##  use the first five layers from a pre-existing model\n",
    "##  see example at https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113\n",
    "##   ML -> /share/lazy/sokoloff/ML\n",
    "\n",
    "path = 'run_stats.pyt'\n",
    "load_full_state(model, optimizer, path)\n",
    "# For other pretrained models, go to MLFlow and find the path for \"run_stats.pyt\"\n",
    "pretrained_dict = torch.load('/share/lazy/sokoloff/ML/02June2020_CNN5Layer_Ca_yetAnother200epochs_K/02June2020_CNN5Layer_Ca_yetAnother200epochs_K_final.pyt')\n",
    "load_full_state(model, optimizer, pretrained_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the model's weight matricies to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \n",
    "\n",
    "\n",
    "\n",
    "The body of this loop runs once per epoch. Results is a named tuple of values (loss per epoch for training and validation, time each). Start by setting up a plot first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, tax, lax, lines = dual_train_plots()\n",
    "fig = ax.figure\n",
    "plt.tight_layout()\n",
    "# This gets built up during the run - do not rerun this cell\n",
    "results = pd.DataFrame([], columns=Results._fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('for model: ', model)   \n",
    "run_name = 'SCNN-ACNN freeze'\n",
    "# Create an mlflow run\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log parameters of the model\n",
    "    for key, value in vars(args).items():\n",
    "        print(key, value)\n",
    "        mlflow.log_param(key, value)\n",
    "    \n",
    "    # Log parameter count in the model\n",
    "    mlflow.log_param('Parameters', count_parameters(model))\n",
    "    \n",
    "    # Begin run\n",
    "    for result in trainNet(model, optimizer, loss,\n",
    "                            train_loader, val_loader,\n",
    "                            args.epochs+args.epoch_start, epoch_start=args.epoch_start,\n",
    "                            notebook=True, device=device):\n",
    "\n",
    "        result = result._asdict()\n",
    "        results = results.append(pd.Series(result), ignore_index=True)\n",
    "        xs = results.index\n",
    "\n",
    "        # Update the plot above\n",
    "        lines['train'].set_data(results.index, results.cost)\n",
    "        lines['val'].set_data(results.index, results.val)\n",
    "\n",
    "        #filter first cost epoch (can be really large)\n",
    "        max_cost = max(max(results.cost if len(results.cost)<2 else results.cost[1:]), max(results.val))\n",
    "        min_cost = min(min(results.cost), min(results.val))\n",
    "    \n",
    "        # The plot limits need updating too\n",
    "        ax.set_ylim(min_cost*.9, max_cost*1.1)  \n",
    "        ax.set_xlim(-.5, len(results.cost) - .5)\n",
    "    \n",
    "        replace_in_ax(lax, lines['eff'], xs, results['eff_val'].apply(lambda x: x.eff_rate))\n",
    "        replace_in_ax(tax, lines['fp'], xs, results['eff_val'].apply(lambda x: x.fp_rate))\n",
    "    \n",
    "        # Redraw the figure\n",
    "        fig.canvas.draw()\n",
    "        plt.tight_layout()\n",
    "        fig.savefig('plot.png')\n",
    "            \n",
    "            \n",
    "        ## MLFLOW ##\n",
    "        # Log metrics\n",
    "        mlflow.log_metric('Efficiency', result['eff_val'].eff_rate, result['epoch'])\n",
    "        mlflow.log_metric('False Positive Rate',  result['eff_val'].fp_rate, result['epoch'])\n",
    "        mlflow.log_metric('Validation Loss',  result['val'], result['epoch'])\n",
    "        mlflow.log_metric('Training Loss',  result['cost'], result['epoch'])\n",
    "            \n",
    "        # Log tags\n",
    "#        mlflow.set_tag('Optimizer', 'Adam')\n",
    "#        mlflow.set_tag('Kernel size', 'Mixed')\n",
    "#        mlflow.set_tag('Skip connections', '4')\n",
    "#        mlflow.set_tag('Activation', 'Softplus')\n",
    "#        mlflow.set_tag('Mid Activation', 'Relu')\n",
    "\n",
    "        # Save model state dictionary, optimizer state dictionary, and epoch number\n",
    "        torch.save({\n",
    "            'model':model.state_dict(),\n",
    "            'optimizer':optimizer.state_dict(),\n",
    "            'epoch':args.epochs+result['epoch']\n",
    "            }, 'run_stats.pyt')\n",
    "        # Save the run stats into mlflow\n",
    "        mlflow.log_artifact('run_stats.pyt')\n",
    "            \n",
    "        # Save a diagram of the architecture\n",
    "        HL.transforms.Fold(\"Conv\", \"Conv\"),\n",
    "        HL.build_graph(model, torch.zeros([args.batch_size, 1, 4000]).to(device)).save('architecture', format='png')\n",
    "        mlflow.log_artifact('architecture.png')\n",
    "        \n",
    "        # log the code for the model architecture\n",
    "#        mlflow.log_artifact('architecture.txt')\n",
    "        \n",
    "        # save plot\n",
    "        mlflow.log_artifact('plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goofit-june2020",
   "language": "python",
   "name": "goofit-june2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
